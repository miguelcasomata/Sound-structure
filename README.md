# Sound-structure (Final Coursework)


- INTRODUCTION

This report will detailed explain theoretical background about live coding, music programming and how to use Sonic Pi in order to be able to create my own live-coding musical piece. Furthermore, the weaknesses and strenghts of the project will be considered in order to obtain criticism about the experience.

- THEORETICAL BACKGROUND

The computer has for some time been viewed as an amazingly appealing tool for making and controlling sound. Its exactness, opportunities for new tones, and potential for fantastical robotization make it a captivating stage for exploring different avenues regarding and making music. A programming language is an assortment of syntactic and semantic guidelines for indicating these directions, and in the long run for giving the interpretation from human-composed projects to the comparing guidelines PCs complete. The programming language goes about as an intermediary between human goal and the relating directions that sound good to a computer.

Live coding is a programming practice that works through the constant execution of code and in this manner incomprehensibly changes the view of traditional computer programming regarding merging structure, coding and investigating stages into one single procedure. This means that immediately putting code into action and turning out results enables a direct verification of whether a program works at all, and if the results make sense as expected or need to be modified. Melodic live coding may in this manner motivate individuals through catching the expertise of figuring out how to code their own spontaneous creations or structures.

- HISTORICAL BACKGROUND

BEFORE COMPUTERS - The idea of programming computational automata to make music can be traced back to as early as  1843. Ada Lovelace, while working with Charles Babbage, expounded on the utilizations of the hypothetical Expository Motor, the replacement to Babbage's well known Contrast Motor. The first Distinction Engine was mainly a "calculating machine" while the Analytic Scientific (which was never designed) was to contain systems for choice and circling, both essential to genuine programmability.

As electronic  music evolved, analog synthesizers  gained  popularity  (around  the  1960s). 
They supported interconnecting and interchangeable sound processing modules.  There is a  certain  level  of  programmability  involved,  and  this  block-based  paradigm  influenced later design of digital synthesis systems. One significant pattern in this setting is that as computers expanded in computational power and capacity, programming dialects would in general become progressively high-level, abstracting more details of the hidden framework. This, as we will see, enormously affected the development of how we program music


